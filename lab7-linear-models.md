# Лабораторная работа №7: Линейная Регрессия

Теория:
* https://habr.com/ru/company/ods/blog/323890/
* https://habr.com/ru/post/278513/
* https://habr.com/ru/post/279117/

Задание:

0.0. Найти и загрузить датасет, подгодящий для регрессии

0.1. Временно удалить категориальные / бинарные признаки, оставив только вещественные (потом вернёмся к ним позже).

0.5. Визуализировать heatmap-матрицу кореллированности признаков. См. [пример](https://stackoverflow.com/questions/39409866/correlation-heatmap).

0.6. Визуализировать взаимосвязь между target-переменной и каждым из признаком (с помощью `srs.pairplot` или `pandas.plotting.scatter_matrix` или как-то ещё). Лучше всего, если будете строить диаграмму попарного распределения не между ВСЕМИ парами признаков, а только между признаками и целевой переменной. См. [пример](https://stackoverflow.com/questions/31966494/compare-1-independent-vs-many-dependent-variables-using-seaborn-pairplot-in-an-h).

0.8. Разделить на обучающую и тестовую выборки

1.: Опробовать линейную регрессию

1.1. Обучить модель линейной регрессии (`LinearRegression`)

1.2. Вывести метрики MAE, MSE и R2 на обущающем и тестовом наборе

1.3. Вывести `model.coef_` и `model.intercept_`

1.4. Построить график (`barh`) с важностью коэфициентов при соответствующих признаках (строится точно так же как мы строили графики для feature_importance в теме с деревьями)  
     (желательно если сверху вниз будут идти коэффициенты по убыванию, а названия соответствующих признаков подписаны по вертикальной оси

2.: Опробовать регрессию `Lasso`

2.1. Обучить модель регрессии (`Lasso`), с помощью `GridSearchCV` найти наилучший параметр `alpha`, дальше работаем с лучше моделью

2.2. Для наилучшей модели вывести метрики MAE, MSE и R2 на обущающем и тестовом наборе

2.3. Для наилучшей модели вывести `model.coef_` и `model.intercept_`

2.4. Для наилучшей модели построить график (`barh`) с важностью коэфициентов при соответствующих признаках

3.: Опробовать регрессию `Ridge`

3.1. Обучить модель регрессии (`Ridge`), с помощью `GridSearchCV` найти наилучший параметр `alpha`, дальше работаем с лучше моделью

3.2. Для наилучшей модели вывести метрики MAE, MSE и R2 на обущающем и тестовом наборе

3.3. Для наилучшей модели вывести `model.coef_` и `model.intercept_`

3.4. Для наилучшей модели построить график (`barh`) с важностью коэфициентов при соответствующих признаках

4.: Опробовать регрессию `ElasticNet`

4.1. Обучить модель регрессии (`ElasticNet`), с помощью `GridSearchCV` найти наилучший параметры `alpha` и `l1_ratio` (в пределах 0:1), дальше работаем с лучше моделью
	
4.2. Для наилучшей модели вывести метрики MAE, MSE и R2 на обущающем и тестовом наборе

4.3. Для наилучшей модели вывести `model.coef_` и `model.intercept_`

4.4. Для наилучшей модели построить график (`barh`) с важностью коэфициентов при соответствующих признаках

5.0. Выбрать наилучшую модель, написать её ошибку MAE, MSE и R2 на тестовом наборе

5.1. Возвращаем категориальные / бинарные признаки на место в датасет, категориальные признаки преобразуем в набор бинарных через `pd.get_dummies( ..., drop_first = True )`.

5.2. Смотрим насколько изменились метрики MAE и MSE на тестовом наборе, отображаем их

5.3. Прогоняем наш датасет (X), который уже обогащён бинарными признаками, через `StandardScaler`, обучаем найденную на предыдущих шагах лучшую модель новыми данными, пишем получивнуюся ошибку MAE, MSE и R2 на тестовом наборе

5.4. Выводим итоговый набор графика с коэффициентами, (желательно если сверху вниз будут идти коэффициенты по убыванию, а названия соответствующих признаков подписаны по вертикальной оси).

При поиске наилучшего регрессора с помощью `GridSearchCV` для извлечения параметров лучшей модели используем атрибут с объектом лучшей модели: `gs.best_estimator_`, например извлекаем вектор коэффициентов: `gs.best_estimator_.coef_`


Датасет нужен в идеале с категориальными / бинарными признаками, чтобы выполнить полноценно задание 5.1., 5.2.
В этом случае балл за задание будет повышен.
Если у вас только вещественные признаки, тогда сделать пп (5.1.) и (5.2) не сможете, в этом случае — стандартный балл.

Логика всего задания проста:
1. Ищем наилучший регрессор на вещественных признаках
2. Пробуем добавить категориальные (преобразованные в бинарные), смотрим как изменилось качество, стала ли модель лучше работать
3. Пробуем отскалировать признаки через StandardScaler, смотрим, повлияло ли это на качество модели.


